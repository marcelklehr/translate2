{
	"llama": [
		{
			"model_file": "madlad400-3b-mt-q8_0.gguf",
			"n_ctx": 8192,
			"max_tokens": 8192,
			"n_batch": 512
		},
		{
			"model_file": "madlad400-7b-mt-bt-q8_0.gguf",
			"n_ctx": 4096,
			"max_tokens": 4096,
			"n_batch": 256
		}
	]
}
